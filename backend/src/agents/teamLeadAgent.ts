import { Task, TaskStatus } from "@prisma/client";
import { callLLM } from "../llm/llmClient";
import { getAgentConfig } from "../llm/modelRegistry";
import { emitTaskUpdate, emitAgentUpdate, emitLog } from "../websocket/socketServer";
import { prisma } from "../lib/prisma";
import { populationManager } from "../services/evolution/PopulationManager";
import { quickEUpdate, getRoleReward } from "../services/evolution/EvolutionaryRewardHelper";

export class TeamLeadAgent {
  async reviewTask(
    task: Task,
    designContext: any,
    previousAttempts: any[]
  ): Promise<any> {
    const isDesignTask = task.requiredRole === "DESIGNER";

    const CODE_REVIEW_PROMPT = `
You are a Team Lead Engineer (L6). Your job is to REVIEW the work of a Developer Agent.
You are the Quality Gatekeeper. You prevent bad code from merging.

INPUT:
- Task: ${task.title}
- Design Context: ${JSON.stringify(designContext)}
- Previous Attempts: ${JSON.stringify(previousAttempts)}
- Current Output: ${task.outputArtifact || "No output"}

YOUR PROCESS:
1. Read the Design Context (ADR, Proposal). Does the code match the design?
2. Run a MENTAL PRE-REVIEW CHECKLIST:
   - API Contract: Are inputs/outputs correct?
   - Security: Any SQL injection, XSS, or auth bypass risks?
   - Performance: Any O(n^2) loops or N+1 queries?
   - Complexity: Is the code readable?
3. DECIDE:
   - "APPROVE": Code is good.
   - "REQUEST_CHANGES": Code has issues. Provide specific feedback.
   - "ESCALATE": You are unsure or the design is flawed.

OUTPUT JSON ONLY:
{
  "decision": "APPROVE" | "REQUEST_CHANGES" | "ESCALATE",
  "feedback": [
    {
      "file": "path/to/file",
      "line": 123,
      "issue": "Brief description of issue",
      "explanation": "Why this is bad",
      "patch_hint": "One-line code fix suggestion"
    }
  ],
  "audit_note": "Short summary for the audit log",
  "mentoring_tip": "Optional: A general coding tip based on the errors found"
}
`;

    const DESIGN_REVIEW_PROMPT = `
You are a Creative Director and Head of Product. Your job is to REVIEW the Design Package generated by a Designer Agent.
You are the Brand Guardian. You prevent ugly or unusable designs from proceeding.

INPUT:
- Task: ${task.title}
- Design Brief: ${JSON.stringify(task.contextPacket || {})}
- Design Package: ${task.outputArtifact || "No output"}

YOUR PROCESS:
1. Does the design meet the Design Brief goals?
2. Is the "Recommended Direction" strong and distinct?
3. Are the User Journey and Wireframes logical?
4. Is the Accessibility Report passing?
5. DECIDE:
   - "APPROVE": Design is excellent.
   - "REQUEST_CHANGES": Design needs work. Provide specific feedback.
   - "ESCALATE": Design is fundamentally flawed or brief is unclear.

OUTPUT JSON ONLY:
{
  "decision": "APPROVE" | "REQUEST_CHANGES" | "ESCALATE",
  "feedback": [
    {
      "section": "Wireframes",
      "issue": "Navigation is confusing",
      "suggestion": "Add a home button"
    }
  ],
  "audit_note": "Short summary of the review",
  "mentoring_tip": "Optional: A design tip"
}
`;

    const systemPrompt = isDesignTask
      ? DESIGN_REVIEW_PROMPT
      : CODE_REVIEW_PROMPT;

    // If task has output and has been reviewed before, be more lenient
    const hasOutput = task.outputArtifact && task.outputArtifact.length > 50;
    const retryCount = (task.retryCount as number) || 0;

    // Auto-approve if we have reasonable output and it's been through review cycles
    if (hasOutput && retryCount >= 2) {
      console.log(
        `[TeamLead] Auto-approving task with output after ${retryCount} cycles`
      );
      return {
        decision: "APPROVE",
        feedback: [],
        audit_note: `Auto-approved: Task has valid output after ${retryCount} review cycles`,
        mentoring_tip:
          "Code looks functional - approved to prevent infinite loops",
      };
    }

    const config = await getAgentConfig("TeamLead");
    const response = await callLLM(config, [
      { role: "system", content: systemPrompt },
      { role: "user", content: "Review this task output." },
    ]);

    try {
      const cleanResponse = response.content
        .replace(/```json/g, "")
        .replace(/```/g, "")
        .trim();
      const parsed = JSON.parse(cleanResponse);

      // If LLM returns invalid decision, default to APPROVE if there's output
      if (
        !["APPROVE", "REQUEST_CHANGES", "ESCALATE"].includes(parsed.decision)
      ) {
        console.log(
          `[TeamLead] Invalid decision '${parsed.decision}', defaulting to APPROVE`
        );
        parsed.decision = hasOutput ? "APPROVE" : "REQUEST_CHANGES";
      }

      return parsed;
    } catch (e) {
      console.error("Failed to parse Team Lead response", e);
      // If parsing fails but we have output, approve it
      if (hasOutput) {
        return {
          decision: "APPROVE",
          feedback: [],
          audit_note: "Auto-approved due to parse error with valid output",
        };
      }
      return {
        decision: "REQUEST_CHANGES",
        feedback: [
          { issue: "Could not review - please ensure output is complete" },
        ],
        audit_note: "JSON Parse Error",
      };
    }
  }
}

export async function runTeamLeadAgentOnce() {
  // Find tasks waiting for review (sent by QA after passing)
  const tasksToReview = await prisma.task.findMany({
    where: { status: "IN_REVIEW" },
    include: {
      module: {
        select: { projectId: true },
      },
    },
    take: 5, // Process a few at a time
  });

  if (tasksToReview.length === 0) return;

  console.log(`[TeamLead] Found ${tasksToReview.length} tasks to review.`);

  const agent = new TeamLeadAgent();

  for (const task of tasksToReview) {
    console.log(`[TeamLead] Reviewing Task ${task.id}: ${task.title}`);

    // Find the TeamLead agent for this project to track its stats
    const projectId = task.module?.projectId;
    let teamLeadAgent = null;
    if (projectId) {
      teamLeadAgent = await prisma.agent.findFirst({
        where: {
          id: { startsWith: `proj_${projectId}` },
          role: { contains: "TeamLead", mode: "insensitive" },
        },
      });
    }

    try {
      // Fetch context (Design, History)
      const designContext = task.designContext || {};
      const history = (task.history as any[]) || [];

      // Safety: if this task has cycled through reviews too many times,
      // auto-approve to break potential infinite loops. This prevents
      // tasks from bouncing between QA and TeamLead forever.
      const retries = (task.retryCount as number) || 0;
      if (retries > 3) {
        console.log(
          `[TeamLead] Auto-approving Task ${task.id} after ${retries} retries`
        );
        await prisma.task.update({
          where: { id: task.id },
          data: {
            status: "COMPLETED",
            reviewDecision: "AUTO_APPROVED",
            reviewFeedback: {
              note: "Auto-approved after repeated review cycles",
            } as any,
            lastReviewBy: "TeamLeadAgent",
            lastReviewAt: new Date(),
          } as any,
        });

        // EVOLUTIONARY: Reward implementing agent with E-value
        if (task.assignedToAgentId) {
          try {
            await quickEUpdate(task.assignedToAgentId, getRoleReward('MidDev', 'success'), 'Auto-approved after retries');
          } catch (e) {
            console.error(`[TeamLead] Failed to update agent E-value:`, e);
          }
        }

        // EVOLUTIONARY: Reward TeamLead for review
        if (teamLeadAgent) {
          await quickEUpdate(teamLeadAgent.id, getRoleReward('TeamLead', 'review'), 'Auto-approval review');
        }

        const updatedTask = await prisma.task.findUnique({
          where: { id: task.id },
        });
        if (updatedTask) emitTaskUpdate(updatedTask);
        continue;
      }

      const reviewResult = await agent.reviewTask(task, designContext, history);

      let newStatus: TaskStatus = task.status;

      if (reviewResult.decision === "APPROVE") {
        console.log(
          `[TeamLead] ✅ Approved Task ${task.id} - marking COMPLETED`
        );
        newStatus = "COMPLETED"; // Final approval - task is done!
      } else if (reviewResult.decision === "REQUEST_CHANGES") {
        console.log(`[TeamLead] ❌ Requested Changes for Task ${task.id}`);
        newStatus = "NEEDS_REVISION"; // Send back to developer for fixes
        // Track that review requested changes to help detect loops
        // increment retryCount so QA/Dev cycles are counted
        try {
          await prisma.task.update({
            where: { id: task.id },
            data: { retryCount: { increment: 1 } },
          });
        } catch (e) {
          console.error(
            `[TeamLead] Failed to increment retryCount for ${task.id}:`,
            e
          );
        }
      } else if (reviewResult.decision === "ESCALATE") {
        console.log(`[TeamLead] ⚠️ Escalated Task ${task.id}`);
        newStatus = "WAR_ROOM"; // Needs senior attention
      }

      await prisma.task.update({
        where: { id: task.id },
        data: {
          status: newStatus,
          reviewDecision: reviewResult.decision,
          reviewFeedback: reviewResult as any,
          lastReviewBy: "TeamLeadAgent",
          lastReviewAt: new Date(),
        } as any,
      });

      // EVOLUTIONARY: Update implementing agent with E-value for approval
      if (newStatus === "COMPLETED" && task.assignedToAgentId) {
        await quickEUpdate(task.assignedToAgentId, getRoleReward('MidDev', 'success'), 'Task approved');
      }

      // EVOLUTIONARY: Update TeamLead E-value for completing review
      if (teamLeadAgent) {
        await quickEUpdate(teamLeadAgent.id, getRoleReward('TeamLead', 'review'), 'Review completed');
      }

      // Emit WebSocket update for real-time UI
      const updatedTask = await prisma.task.findUnique({
        where: { id: task.id },
      });
      if (updatedTask) emitTaskUpdate(updatedTask);
    } catch (error) {
      console.error(`[TeamLead] Error reviewing task ${task.id}:`, error);
    }
  }
}
